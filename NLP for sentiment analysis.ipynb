{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Analysis\n",
    "You’ll begin by installing some prerequisites, including NLTK itself as well as specific resources you’ll need throughout this tutorial.\n",
    "\n",
    "First, use pip to install NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #python3 -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK will display a download manager showing all available and installed resources. Here are the ones you’ll need to download for this tutorial:\n",
    "\n",
    "names: A list of common English names compiled by Mark Kantrowitz\n",
    "stopwords: A list of really common words, like articles, pronouns, prepositions, and conjunctions\n",
    "state_union: A sample of transcribed State of the Union addresses by different US presidents, compiled by Kathleen Ahrens\n",
    "twitter_samples: A list of social media phrases posted to Twitter\n",
    "movie_reviews: Two thousand movie reviews categorized by Bo Pang and Lillian Lee\n",
    "averaged_perceptron_tagger: A data model that NLTK uses to categorize words into their part of speech\n",
    "vader_lexicon: A scored list of words and jargon that NLTK references when performing sentiment analysis, created by C.J. Hutto and Eric Gilbert\n",
    "punkt: A data model created by Jan Strunk that NLTK uses to split full texts into word lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick way to download specific resources directly from the console is to pass a list to nltk.download():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sushanth S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\n",
    "...     \"names\",\n",
    "...     \"stopwords\",\n",
    "...     \"state_union\",\n",
    "...     \"twitter_samples\",\n",
    "...     \"movie_reviews\",\n",
    "...     \"averaged_perceptron_tagger\",\n",
    "...     \"vader_lexicon\",\n",
    "...     \"punkt\",\n",
    "... ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to C:\\Users\\Sushanth\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "\n",
    "#import tensorflow as tf\n",
    "#shakespeare_url=\"https://homl.info/shakespeare\"\n",
    "#filepath=tf.keras.utils.get_file('shakespeare.txt',shakespeare_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = nltk.corpus.movie_reviews.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Data\n",
    "NLTK provides a number of functions that you can call with few or no arguments that will help you meaningfully analyze text before you even touch its machine learning capabilities. Many of NLTK’s utilities are helpful in preparing your data for more advanced analysis.\n",
    "\n",
    "Soon, you’ll learn about frequency distributions, concordance, and collocations. But first, you need some data.\n",
    "\n",
    "Start by loading the State of the Union corpus you downloaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you build a list of individual words with the corpus’s .words() method, but you use str.isalpha() to include only the words that are made up of letters. Otherwise, your word list may end up with “words” that are only punctuation marks.\n",
    "\n",
    "Have a look at your list. You’ll notice lots of little words like “of,” “a,” “the,” and similar. These common words are called stop words, and they can have a negative effect on your analysis because they occur so often in the text. Thankfully, there’s a convenient way to filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to specify english as the desired language since this corpus contains stop words in various languages.\n",
    "\n",
    "Now you can remove stop words from your original word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in words if w.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all words in the stopwords list are lowercase, and those in the original list may not be, you use str.lower() to account for any discrepancies. Otherwise, you may end up with mixedCase or capitalized stop words still in your list.\n",
    "\n",
    "While you’ll use corpora provided by NLTK for this tutorial, it’s possible to build your own text corpora from any source. Building a corpus can be as simple as loading some plain text or as complex as labeling and categorizing each sentence. Refer to NLTK’s documentation for more information on how to work with corpus readers.\n",
    "\n",
    "For some quick analysis, creating a corpus could be overkill. If all you need is a word list, there are simpler ways to achieve that goal. Beyond Python’s own string manipulation methods, NLTK provides nltk.word_tokenize(), a function that splits raw text into individual words. While tokenization is itself a bigger topic (and likely one of the steps you’ll take when creating a custom corpus), this tokenizer delivers simple word lists really well.\n",
    "\n",
    "To use it, call word_tokenize() with the raw text you want to split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "text = \"\"\"For some quick analysis creating a corpus could be overkill\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'some', 'quick', 'analysis', 'creating', 'a', 'corpus', 'could', 'be',\n",
      " 'overkill']\n"
     ]
    }
   ],
   "source": [
    "pprint(nltk.word_tokenize(text), width=79, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a workable word list! Remember that punctuation will be counted as individual words, so use str.isalpha() to filter them out later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Frequency Distributions\n",
    "Now you’re ready for frequency distributions. A frequency distribution is essentially a table that tells you how many times each word appears within a given text. In NLTK, frequency distributions are a specific object type implemented as a distinct class called FreqDist. This class provides useful operations for word frequency analysis.\n",
    "\n",
    "To build a frequency distribution with NLTK, construct the nltk.FreqDist class with a word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('must', 1568),\n",
       " ('people', 1291),\n",
       " ('world', 1128),\n",
       " ('year', 1097),\n",
       " ('America', 1076),\n",
       " ('us', 1049),\n",
       " ('new', 1049),\n",
       " ('Congress', 1014),\n",
       " ('years', 827),\n",
       " ('American', 784)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    must   people    world     year  America       us      new Congress    years American \n",
      "    1568     1291     1128     1097     1076     1049     1049     1014      827      784 \n"
     ]
    }
   ],
   "source": [
    "fd.tabulate(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods allow you to quickly determine frequently used words in a sample. With .most_common(), you get a list of tuples containing each word and how many times it appears in your text. You can get the same information in a more readable format with .tabulate().\n",
    "\n",
    "In addition to these two methods, you can use frequency distributions to query particular words. You can also use them as iterators to perform some custom analysis on word properties.\n",
    "\n",
    "For example, to discover differences in case, you can query for different variations of the same word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"america\"]  # Note this doesn't result in a KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"AMERICA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These return values indicate the number of times each word occurs exactly as given.\n",
    "\n",
    "Since frequency distribution objects are iterable, you can use them within list comprehensions to create subsets of the initial distribution. You can focus these subsets on properties that are useful for your own analysis.\n",
    "\n",
    "Try creating a new frequency distribution that’s based on the initial one but normalizes all words to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fd = nltk.FreqDist([w.lower() for w in fd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a more accurate representation of word usage regardless of case.\n",
    "\n",
    "Think of the possibilities: You could create frequency distributions of words starting with a particular letter, or of a particular length, or containing certain letters. Your imagination is the limit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Concordance and Collocations\n",
    "In the context of NLP, a concordance is a collection of word locations along with their context. You can use concordances to find:\n",
    "\n",
    "How many times a word appears\n",
    "Where each occurrence appears\n",
    "What words surround each occurrence\n",
    "In NLTK, you can do this by calling .concordance(). To use it, you need an instance of the nltk.Text class, which can also be constructed with a word list.\n",
    "\n",
    "Before invoking .concordance(), build a new word list from the original corpus text so that all the context, even stop words, will be there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(nltk.corpus.state_union.words())\n",
    "text.concordance(\"america\", lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that .concordance() already ignores case, allowing you to see the context of all case variants of a word in order of appearance. Note also that this function doesn’t show you the location of each word in the text.\n",
    "\n",
    "Additionally, since .concordance() only prints information to the console, it’s not ideal for data manipulation. To obtain a usable list that will also give you information about the location of each occurrence, use .concordance_list():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n"
     ]
    }
   ],
   "source": [
    "concordance_list = text.concordance_list(\"america\", lines=2)\n",
    "for entry in concordance_list:\n",
    "    print(entry.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".concordance_list() gives you a list of ConcordanceLine objects, which contain information about where each word occurs as well as a few more properties worth exploring. The list is also sorted in order of appearance.\n",
    "\n",
    "The nltk.Text class itself has a few other interesting features. One of them is .vocab(), which is worth mentioning because it creates a frequency distribution for a given text.\n",
    "\n",
    "Revisiting nltk.word_tokenize(), check out how quickly you can create a custom nltk.Text instance and an accompanying frequency distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    is better   than \n",
      "     3      3      3 \n"
     ]
    }
   ],
   "source": [
    "nltk.word_tokenize(\"\"\"Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.\"\"\")\n",
    "text = nltk.Text(words)\n",
    "fd = text.vocab()  # Equivalent to fd = nltk.FreqDist(words)\n",
    "fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".vocab() is essentially a shortcut to create a frequency distribution from an instance of nltk.Text. That way, you don’t have to make a separate call to instantiate a new nltk.FreqDist object.\n",
    "\n",
    "Another powerful feature of NLTK is its ability to quickly find collocations with simple function calls. Collocations are series of words that frequently appear together in a given text. In the State of the Union corpus, for example, you’d expect to find the words United and States appearing next to each other very often. Those two words appearing together is a collocation.\n",
    "\n",
    "Collocations can be made up of two or more words. NLTK provides classes to handle several types of collocations:\n",
    "\n",
    "Bigrams: Frequent two-word combinations\n",
    "Trigrams: Frequent three-word combinations\n",
    "Quadgrams: Frequent four-word combinations\n",
    "NLTK provides specific classes for you to find collocations in your text. Following the pattern you’ve seen so far, these classes are also built from lists of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TrigramCollocationFinder instance will search specifically for trigrams. As you may have guessed, NLTK also has the BigramCollocationFinder and QuadgramCollocationFinder classes for bigrams and quadgrams, respectively. All these classes have a number of utilities to give you information about all identified collocations.\n",
    "\n",
    "One of their most useful tools is the ngram_fd property. This property holds a frequency distribution that is built for each collocation rather than for individual words.\n",
    "\n",
    "Using ngram_fd, you can find the most common collocations in the supplied text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'United', 'States'), 294), (('the', 'American', 'people'), 185)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.ngram_fd.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ('the', 'United', 'States') ('the', 'American', 'people') \n",
      "                          294                           185 \n"
     ]
    }
   ],
   "source": [
    "finder.ngram_fd.tabulate(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don’t even have to create the frequency distribution, as it’s already a property of the collocation finder instance.\n",
    "\n",
    "Now that you’ve learned about some of NLTK’s most useful tools, it’s time to jump into sentiment analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK’s Pre-Trained Sentiment Analyzer\n",
    "NLTK already has a built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner).\n",
    "\n",
    "Since VADER is pretrained, you can get results more quickly than with many other analyzers. However, VADER is best suited for language used in social media, like short sentences with some slang and abbreviations. It’s less accurate when rating longer, structured sentences, but it’s often a good launching point.\n",
    "\n",
    "To use VADER, first create an instance of nltk.sentiment.SentimentIntensityAnalyzer, then use .polarity_scores() on a raw string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll get back a dictionary of different scores. The negative, neutral, and positive scores are related: They all add up to 1 and can’t be negative. The compound score is calculated differently. It’s not just an average, and it can range from -1 to 1.\n",
    "\n",
    "Now you’ll put it to the test against real data using two different corpora. First, load the twitter_samples corpus into a list of strings, making a replacement to render URLs inactive to avoid accidental clicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you use a different corpus method, .strings(), instead of .words(). This gives you a list of raw tweets as strings.\n",
    "\n",
    "Different corpora have different features, so you may need to use Python’s help(), as in help(nltk.corpus.tweet_samples), or consult NLTK’s documentation to learn how to use a given corpus.\n",
    "\n",
    "Now use the .polarity_scores() function of your SentimentIntensityAnalyzer instance to classify tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False RT @stardust193: #AskNigelFarage #AskNigel #UKIP #AskFarage #bbcqt  I never go abroad without medical insurance. I'd never expect another c…\n",
      "> False RT @britainelects: Latest YouGov poll (29 - 30 Apr):\n",
      "LAB - 35% (+1)\n",
      "CON - 34% (-1)\n",
      "UKIP - 12% (-)\n",
      "LDEM - 8% (-1) \n",
      "GRN - 5% (+1)\n",
      "> True Great statement about our ex-servicemen &amp; women by @Nigel_Farage about time the rest of them started doing more  #UKIP #AskNigelFarage\n",
      "> True @ruth_wishart @linannlum imply is an understatement. Hard to see any way back from his garbage. He must have bet Tories are going to win.\n",
      "> True RT @agwhitchurch: Now we know the only way to an economist backed anti-austerity government is SNP, Plaid Cymru &amp; Green coalition https//t…\n",
      "> False \"Die Foreigners! Die!\" Farage - #election2015\n",
      "> True RT @BBCDouglasF: Miliband gift to SNP: I'd rather Tories in power than any SNP deal with Labour (works in England, unlikely to do so in Sco…\n",
      "> False I am the first person to make twinx cry as a 16 year old :)))\n",
      "> True RT @chezally: @theSNP @bjp11scot @NicolaSturgeon @DeidreBrock More important than ever now that Miliband has effectively conceded. #GE2015 …\n",
      "> True @yknoC that monte/doa header :D\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, is_positive() uses only the positivity of the compound score to make the call. You can choose any combination of VADER scores to tweak the classification to your needs.\n",
    "\n",
    "Now take a look at the second corpus, movie_reviews. As the name implies, this is a collection of movie reviews. The special thing about this corpus is that it’s already been classified. Therefore, you can use it to judge the accuracy of the algorithms you choose when rating similar texts.\n",
    "\n",
    "Keep in mind that VADER is likely better at rating tweets than it is at rating long movie reviews. To get better results, you’ll set up VADER to rate individual sentences within the review rather than the entire text.\n",
    "\n",
    "Since VADER needs raw strings for its rating, you can’t use .words() like you did earlier. Instead, make a list of the file IDs that the corpus uses, which you can use later to reference individual reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".fileids() exists in most, if not all, corpora. In the case of movie_reviews, each file corresponds to a single review. Note also that you’re able to filter the list of file IDs by specifying categories. This categorization is a feature specific to this corpus and others of the same type.\n",
    "\n",
    "Next, redefine is_positive() to work on an entire review. You’ll need to obtain that specific review using its file ID and then split it into sentences before rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def is_positive(review_id: str) -> bool:\n",
    "    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".raw() is another method that exists in most corpora. By specifying a file ID or a list of file IDs, you can obtain specific data from the corpus. Here, you get a single review, then use nltk.sent_tokenize() to obtain a list of sentences from the review. Finally, is_positive() calculates the average compound score for all sentences and associates a positive result with a positive review.\n",
    "\n",
    "You can take the opportunity to rate all the reviews and see how accurate VADER is with this setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.00% correct\n"
     ]
    }
   ],
   "source": [
    "shuffle(all_review_ids)\n",
    "correct = 0\n",
    "for review_id in all_review_ids:\n",
    "     if is_positive(review_id):\n",
    "         if review_id in positive_review_ids:\n",
    "             correct += 1\n",
    "     else:\n",
    "         if review_id in negative_review_ids:\n",
    "             correct += 1\n",
    "\n",
    "print(F\"{correct / len(all_review_ids):.2%} correct\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rating all reviews, you can see that only 64 percent were correctly classified by VADER using the logic defined in is_positive().\n",
    "\n",
    "A 64 percent accuracy rating isn’t great, but it’s a start. Have a little fun tweaking is_positive() to see if you can increase the accuracy.\n",
    "\n",
    "In the next section, you’ll build a custom classifier that allows you to use additional features for classification and eventually increase its accuracy to an acceptable level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing NLTK’s Sentiment Analysis\n",
    "NLTK offers a few built-in classifiers that are suitable for various types of analyses, including sentiment analysis. The trick is to figure out which properties of your dataset are useful in classifying each piece of data into your desired categories.\n",
    "\n",
    "In the world of machine learning, these data properties are known as features, which you must reveal and select as you work with your data. While this tutorial won’t dive too deeply into feature selection and feature engineering, you’ll be able to see their effects on the accuracy of classifiers.\n",
    "\n",
    "Selecting Useful Features\n",
    "Since you’ve learned how to use frequency distributions, why not use them as a launching point for an additional feature?\n",
    "\n",
    "By using the predefined categories in the movie_reviews corpus, you can create sets of positive and negative words, then determine which ones occur most frequently across each set. Begin by excluding unwanted words and building the initial category groups:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, you also add words from the names corpus to the unwanted list on line 2 since movie reviews are likely to have lots of actor names, which shouldn’t be part of your feature sets. Notice pos_tag() on lines 14 and 18, which tags words by their part of speech.\n",
    "\n",
    "It’s important to call pos_tag() before filtering your word lists so that NLTK can more accurately tag all words. skip_unwanted(), defined on line 4, then uses those tags to exclude nouns, according to NLTK’s default tag set.\n",
    "\n",
    "Now you’re ready to create the frequency distributions for your custom feature. Since many words are present in both positive and negative sets, begin by finding the common set so you can remove it from the distribution objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "frequency_distribution = FreqDist(positive_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shrek', 23),\n",
       " ('fei', 22),\n",
       " ('ordell', 20),\n",
       " ('soviet', 16),\n",
       " ('kimble', 16),\n",
       " ('en', 14),\n",
       " ('addresses', 14),\n",
       " ('lovingly', 14),\n",
       " ('nello', 14),\n",
       " ('horned', 13),\n",
       " ('kudos', 12),\n",
       " ('supreme', 12),\n",
       " ('flynt', 12),\n",
       " ('conveys', 11),\n",
       " ('narrates', 11),\n",
       " ('broadcast', 11),\n",
       " ('masterfully', 11),\n",
       " ('criticized', 10),\n",
       " ('apostle', 10),\n",
       " ('argento', 10)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_distribution.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27f732da488>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_distribution.plot(20, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you’re left with unique positive and negative words in each frequency distribution object, you can finally build sets from the most common words in each distribution. The amount of words in each set is something you could tweak in order to determine its effect on sentiment analysis.\n",
    "\n",
    "This is one example of a feature you can extract from your data, and it’s far from perfect. Looking closely at these sets, you’ll notice some uncommon names and words that aren’t necessarily positive or negative. Additionally, the other NLTK tools you’ve learned so far can be useful for building more features. One possibility is to leverage collocations that carry positive meaning, like the bigram “thumbs up!”\n",
    "\n",
    "Here’s how you can set up the positive and negative bigram finders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])\n",
    "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is up to you! Try different combinations of features, think of ways to use the negative VADER scores, create ratios, polish the frequency distributions. The possibilities are endless!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Using a Classifier\n",
    "With your new feature set ready to use, the first prerequisite for training a classifier is to define a function that will extract features from a given piece of data.\n",
    "\n",
    "Since you’re looking for positive movie reviews, focus on the features that indicate positivity, including VADER scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                wordcount += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "\n",
    "    # Adding 1 to the final compound score to always have positive numbers\n",
    "    # since some classifiers you'll use later don't work with negative numbers.\n",
    "    features[\"mean_compound\"] = mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = mean(positive_scores)\n",
    "    features[\"wordcount\"] = wordcount\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract_features() should return a dictionary, and it will create three features for each piece of text:\n",
    "\n",
    "The average compound score\n",
    "The average positive score\n",
    "The amount of words in the text that are also part of the top 100 words in all positive reviews\n",
    "In order to train and evaluate a classifier, you’ll need to build a list of features for each text you’ll analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in this list of features needs to be a tuple whose first item is the dictionary returned by extract_features and whose second item is the predefined category for the text. After initially training the classifier with some data that has already been categorized (such as the movie_reviews corpus), you’ll be able to classify new data.\n",
    "\n",
    "Training the classifier involves splitting the feature set so that one portion can be used for training and the other for evaluation, then calling .train():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               wordcount = 3                 pos : neg    =     11.3 : 1.0\n",
      "               wordcount = 2                 pos : neg    =      3.1 : 1.0\n",
      "               wordcount = 0                 neg : pos    =      1.9 : 1.0\n",
      "               wordcount = 1                 pos : neg    =      1.7 : 1.0\n",
      "           mean_positive = 0.09671052631578947    pos : neg    =      1.0 : 1.0\n",
      "           mean_positive = 0.159             pos : neg    =      1.0 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6566666666666666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use 1/4 of the set for training\n",
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
    "classifier.show_most_informative_features(10)\n",
    "\n",
    "nltk.classify.accuracy(classifier, features[train_count:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you’re shuffling the feature list, each run will give you different results. In fact, it’s important to shuffle the list to avoid accidentally grouping similarly classified reviews in the first quarter of the list.\n",
    "\n",
    "Adding a single feature has marginally improved VADER’s initial accuracy, from 64 percent to 67 percent. More features could help, as long as they truly indicate how positive a review is. You can use classifier.show_most_informative_features() to determine which features are most indicative of a specific property.\n",
    "\n",
    "To classify new data, find a movie review somewhere and pass it to classifier.classify(). You can also use extract_features() to tell you exactly how it was scored:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was it correct? Based on the scoring output from extract_features(), what can you improve?\n",
    "\n",
    "Feature engineering is a big part of improving the accuracy of a given algorithm, but it’s not the whole story. Another strategy is to use and compare different classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Additional Classifiers\n",
    "NLTK provides a class that can use most classifiers from the popular machine learning framework scikit-learn.\n",
    "\n",
    "Many of the classifiers that scikit-learn provides can be instantiated quickly since they have defaults that often work well. In this section, you’ll learn how to integrate them within NLTK to classify linguistic data.\n",
    "\n",
    "Installing and Importing scikit-learn\n",
    "Like NLTK, scikit-learn is a third-party Python library, so you’ll have to install it with pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these classifiers imported, you’ll first have to instantiate each one. Thankfully, all of these have pretty good defaults and don’t require much tweaking.\n",
    "\n",
    "To aid in accuracy evaluation, it’s helpful to have a mapping of classifier names and their instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use these instances for training and accuracy evaluation.\n",
    "\n",
    "Using scikit-learn Classifiers With NLTK\n",
    "Since NLTK allows you to integrate scikit-learn classifiers directly into its own classifier class, the training and classification processes will use the same methods you’ve already seen, .train() and .classify().\n",
    "\n",
    "You’ll also be able to leverage the same features list you built earlier by means of extract_features(). To refresh your memory, here’s how you built the features list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features list contains tuples whose first item is a set of features given by extract_features(), and whose second item is the classification label from preclassified data in the movie_reviews corpus.\n",
    "\n",
    "Since the first half of the list contains only positive reviews, begin by shuffling it, then iterate over all classifiers to train and evaluate each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.67% - BernoulliNB\n",
      "65.93% - ComplementNB\n",
      "66.27% - MultinomialNB\n",
      "68.00% - KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._y = np.empty(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype = np.float\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype = np.float\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.00% - DecisionTreeClassifier\n",
      "65.33% - RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:489: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_store_unique_indices = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.67% - LogisticRegression\n",
      "73.27% - MLPClassifier\n",
      "71.40% - AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:749: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "# Use 1/4 of the set for training\n",
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "for name, sklearn_classifier in classifiers.items():\n",
    "    classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "    classifier.train(features[:train_count])\n",
    "    accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n",
    "    print(F\"{accuracy:.2%} - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each scikit-learn classifier, call nltk.classify.SklearnClassifier to create a usable NLTK classifier that can be trained and evaluated exactly like you’ve seen before with nltk.NaiveBayesClassifier and its other built-in classifiers. The .train() and .accuracy() methods should receive different portions of the same list of features.\n",
    "\n",
    "Now you’ve reached over 73 percent accuracy before even adding a second feature! While this doesn’t mean that the MLPClassifier will continue to be the best one as you engineer new features, having additional classification algorithms at your disposal is clearly advantageous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
